{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Power Plant - Data Center Flexibility in ERCOT\n",
    "## Linear Capacity Expansion with Demand-Side Flexibility\n",
    "**Dataset:** Full 52-Week ERCOT Representation (8,760 hours)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive capacity expansion model for the ERCOT grid that:\n",
    "- Co-optimizes generation, storage, and transmission investments\n",
    "- Models a 1 GW data center as a \"Virtual Power Plant\"\n",
    "- Evaluates demand-side flexibility under various scenarios\n",
    "- Uses full annual resolution (8,760 hours) to capture seasonal patterns\n",
    "\n",
    "### Research Questions\n",
    "1. What is the capacity value of flexible computing load?\n",
    "2. How does the strike price (opportunity cost) affect grid investment decisions?\n",
    "3. Does location matter for flexible resources?\n",
    "4. What are the emissions and cost trade-offs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Packages loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load required packages\n",
    "using JuMP\n",
    "using HiGHS\n",
    "using DataFrames, CSV\n",
    "using Statistics, LinearAlgebra\n",
    "using Printf\n",
    "\n",
    "# For reproducibility\n",
    "import Random\n",
    "Random.seed!(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Scenario Setup\n",
    "\n",
    "### Modify parameters to test different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "════════════════════════════════════════════════════════════\n",
      "SCENARIO CONFIGURATION\n",
      "════════════════════════════════════════════════════════════\n",
      "Data Center: 1000.0 MW in Zone 1\n",
      "Strike Price: $300.0/MWh\n",
      "Dataset: 52 weeks (8,760 hrs)\n",
      "Ramping: Enabled\n",
      "Storage: Enabled\n",
      "Transmission Expansion: Enabled\n",
      "════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "source": [
    "# Data Center Parameters\n",
    "DATA_CENTER_MW = 1000.0   # Size of data center load (MW)\n",
    "DATA_CENTER_ZONE = 1      # Location: 1 = West (Wind-rich), 2 = North/East (Demand center), 3 = South (Coast)\n",
    "STRIKE_PRICE = 300.0      # $/MWh - Cost to curtail load (set to 9000 for \"firm\" load)\n",
    "\n",
    "# Model Configuration\n",
    "USE_FULL_YEAR = true                   # true = 52 weeks (8760 hrs), false = 16 weeks (2688 hrs)\n",
    "ENABLE_RAMPING = true                  # Enable/disable ramping constraints for thermal units\n",
    "ENABLE_STORAGE = true                  # Include battery storage options\n",
    "ENABLE_TRANSMISSION_EXPANSION = true   # Allow new transmission capacity\n",
    "\n",
    "# Analysis Options\n",
    "RUN_SENSITIVITY_ANALYSIS = true   # Run multiple strike price scenarios\n",
    "SAVE_HOURLY_RESULTS = true        # Export detailed hourly dispatch\n",
    "\n",
    "# Display configuration\n",
    "println(\"Scenario Configuration:\")\n",
    "println(\"-\" ^ 35)\n",
    "println(\"Data Center: $(DATA_CENTER_MW) MW in Zone $(DATA_CENTER_ZONE)\")\n",
    "println(\"Strike Price: \\$$(STRIKE_PRICE)/MWh\")\n",
    "println(\"Dataset: $(USE_FULL_YEAR ? \"52 weeks (8,760 hrs)\" : \"16 weeks (2,688 hrs)\")\")\n",
    "println(\"Ramping: $(ENABLE_RAMPING ? \"Enabled\" : \"Disabled\")\")\n",
    "println(\"Storage: $(ENABLE_STORAGE ? \"Enabled\" : \"Disabled\")\")\n",
    "println(\"Transmission Expansion: $(ENABLE_TRANSMISSION_EXPANSION ? \"Enabled\" : \"Disabled\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading\n",
    "\n",
    "Load generator characteristics, demand profiles, renewable availability, network topology, and fuel costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ercot_brownfield_expansion\\52_weeks\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "DATA SUMMARY\n",
      "────────────────────────────────────────────────────────────\n",
      "Generators: 55 resources\n",
      "Time steps: 8760 hours\n",
      "Zones: 3 (West, North/East, South/Coast)\n",
      "Transmission lines: 3\n",
      "Fuel types: 6\n",
      "────────────────────────────────────────────────────────────\n",
      "\n",
      "✓ Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Select data path\n",
    "data_folder = USE_FULL_YEAR ? \"52_weeks\" : \"16_weeks\"\n",
    "inputs_path = joinpath(\"ercot_brownfield_expansion\", data_folder)\n",
    "\n",
    "println(\"Loading data from: $(inputs_path)\")\n",
    "\n",
    "# Load generator data\n",
    "generators = DataFrame(CSV.File(joinpath(inputs_path, \"Generators_data.csv\")))\n",
    "\n",
    "# Select essential columns to reduce memory consumption\n",
    "generators = select(generators, \n",
    "    :R_ID, :Resource, :zone, :THERM, :DISP, :NDISP, :STOR, :HYDRO, :RPS, :CES,\n",
    "    :Commit, :Existing_Cap_MW, :Existing_Cap_MWh, :Cap_size, :New_Build, :Max_Cap_MW,\n",
    "    :Inv_cost_per_MWyr, :Fixed_OM_cost_per_MWyr, :Inv_cost_per_MWhyr, :Fixed_OM_cost_per_MWhyr,\n",
    "    :Var_OM_cost_per_MWh, :Start_cost_per_MW, :Start_fuel_MMBTU_per_MW, :Heat_rate_MMBTU_per_MWh, :Fuel,\n",
    "    :Min_power, :Ramp_Up_percentage, :Ramp_Dn_percentage, :Up_time, :Down_time,\n",
    "    :Eff_up, :Eff_down\n",
    ")\n",
    "\n",
    "# Load demand, variability, fuels, and network\n",
    "demand_inputs = DataFrame(CSV.File(joinpath(inputs_path, \"Load_data.csv\")))\n",
    "variability = DataFrame(CSV.File(joinpath(inputs_path, \"Generators_variability.csv\")))\n",
    "variability = variability[:, 2:end]\n",
    "fuels = DataFrame(CSV.File(joinpath(inputs_path, \"Fuels_data.csv\")))\n",
    "network = DataFrame(CSV.File(joinpath(inputs_path, \"Network.csv\")))\n",
    "\n",
    "# Summary statistics\n",
    "println(\"Data Summary\")\n",
    "println(\"─\" ^ 45)\n",
    "println(\"Generators: $(nrow(generators)) resources\")\n",
    "println(\"Time steps: $(nrow(demand_inputs)) hours\")\n",
    "println(\"Zones: 3 (West, North/East, South/Coast)\")\n",
    "println(\"Transmission lines: $(nrow(network))\")\n",
    "println(\"Fuel types: $(nrow(fuels))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Center Integration\n",
    "\n",
    "### Modeling Approach: \"Virtual Generator\"\n",
    "\n",
    "We model the flexible data center with 2 components:\n",
    "1. **Firm Load**: Added to demand in selected zone\n",
    "2. **Virtual Generator**: Represents curtailment (load reduction), $VC = P_{strike}$\n",
    "\n",
    "This formulation allows the optimizer to \"dispatch\" load reduction when marginal cost exceeds the strike price, without requiring binary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1000.0 MW flat load to Zone 1\n",
      "\n",
      "Peak Demands (with data center):\n",
      "  Zone 1 (West): 1000.0 MW\n",
      "  Zone 2 (North/East): 88086.0 MW\n",
      "  Zone 3 (South/Coast): 5632.0 MW\n",
      "  Total System: 94718.0 MW\n",
      "\n",
      "✓ Created 'DataCenter_DR' virtual generator\n",
      "  Capacity: 1000.0 MW\n",
      "  Strike Price (Variable Cost): $300.0/MWh\n",
      "  Zone: 1\n"
     ]
    }
   ],
   "source": [
    "# 1. Add flat load to demand profile\n",
    "demand = select(demand_inputs, :Load_MW_z1, :Load_MW_z2, :Load_MW_z3)\n",
    "\n",
    "# Add data center load to selected zone\n",
    "zone_col = Symbol(\"Load_MW_z$(DATA_CENTER_ZONE)\")\n",
    "demand[!, zone_col] .+= DATA_CENTER_MW\n",
    "\n",
    "println(\"Added $(DATA_CENTER_MW) MW flat load to Zone $(DATA_CENTER_ZONE)\")\n",
    "\n",
    "# Calculate zonal peak demand\n",
    "peak_z1 = maximum(demand.Load_MW_z1)\n",
    "peak_z2 = maximum(demand.Load_MW_z2)\n",
    "peak_z3 = maximum(demand.Load_MW_z3)\n",
    "total_peak = peak_z1 + peak_z2 + peak_z3\n",
    "\n",
    "println(\"\\nPeak Demands (with data center):\")\n",
    "println(\"  Zone 1 (West): $(round(peak_z1, digits=0)) MW\")\n",
    "println(\"  Zone 2 (North/East): $(round(peak_z2, digits=0)) MW\")\n",
    "println(\"  Zone 3 (South/Coast): $(round(peak_z3, digits=0)) MW\")\n",
    "println(\"  Total System: $(round(total_peak, digits=0)) MW\")\n",
    "\n",
    "# 2. Prepare generators DataFrame\n",
    "generators.R_ID = string.(generators.R_ID)\n",
    "\n",
    "# 3. Create virtual generator\n",
    "new_dr = Dict(pairs(generators[1, :]))\n",
    "\n",
    "# Configure DR resource parameters\n",
    "new_dr[:R_ID] = \"DataCenter_DR\"\n",
    "new_dr[:Resource] = \"Demand_Response\"\n",
    "new_dr[:zone] = DATA_CENTER_ZONE\n",
    "new_dr[:THERM] = 0\n",
    "new_dr[:DISP] = 1\n",
    "new_dr[:NDISP] = 0\n",
    "new_dr[:STOR] = 0\n",
    "new_dr[:HYDRO] = 0\n",
    "new_dr[:RPS] = 0\n",
    "new_dr[:CES] = 0\n",
    "new_dr[:Existing_Cap_MW] = DATA_CENTER_MW\n",
    "new_dr[:Max_Cap_MW] = DATA_CENTER_MW\n",
    "new_dr[:New_Build] = 0\n",
    "new_dr[:Var_OM_cost_per_MWh] = STRIKE_PRICE\n",
    "new_dr[:Fuel] = \"DR_Virtual\"\n",
    "new_dr[:Heat_rate_MMBTU_per_MWh] = 0.0\n",
    "new_dr[:Min_power] = 0.0\n",
    "new_dr[:Ramp_Up_percentage] = 1.0\n",
    "new_dr[:Ramp_Dn_percentage] = 1.0\n",
    "new_dr[:Inv_cost_per_MWyr] = 0.0\n",
    "new_dr[:Fixed_OM_cost_per_MWyr] = 0.0\n",
    "new_dr[:Start_cost_per_MW] = 0.0\n",
    "new_dr[:Commit] = 0\n",
    "\n",
    "# Add to generators list\n",
    "push!(generators, new_dr)\n",
    "\n",
    "println(\"Created virtual generator: 'DataCenter_DR'\")\n",
    "println(\"  Capacity: $(DATA_CENTER_MW) MW\")\n",
    "println(\"  Strike Price (Variable Cost): \\$$(STRIKE_PRICE)/MWh\")\n",
    "println(\"  Zone: $(DATA_CENTER_ZONE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pre-Processing and Set Definitions\n",
    "\n",
    "Calculate derived parameters, define optimization sets, and prepare data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n",
      "\n",
      "Time horizon: 8760 hours\n",
      "Annualization factor: 8760.0 hrs/yr\n",
      "\n",
      "Generator subsets:\n",
      "  Total resources (G): 56\n",
      "  Storage (STOR): 3\n",
      "  New-build candidates (NEW): 39\n",
      "  Existing units (OLD): 17\n",
      "  Thermal units (THERM): 20\n",
      "\n",
      "✓ Pre-processing complete\n"
     ]
    }
   ],
   "source": [
    "println(\"Pre-processing data\")\n",
    "\n",
    "# Process time/sample weights\n",
    "hours_per_period = convert(Int64, demand_inputs.Hours_per_period[1])\n",
    "P = convert(Array{Int64}, 1:demand_inputs.Subperiods[1])\n",
    "W = convert(Array{Int64}, collect(skipmissing(demand_inputs.Sub_Weights)))\n",
    "T = convert(Array{Int64}, demand_inputs.Time_index)\n",
    "\n",
    "# Calculate sample weights for annualization\n",
    "sample_weight = zeros(Float64, size(T, 1))\n",
    "t = 1\n",
    "for p in P\n",
    "    for h in 1:hours_per_period\n",
    "        if t <= length(T)\n",
    "            sample_weight[t] = W[p] / hours_per_period\n",
    "            t += 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Time horizon: $(length(T)) hours\")\n",
    "println(\"Annualization factor: $(sum(sample_weight)) hrs/yr\")\n",
    "\n",
    "# Calculate VC (fuel + VOM)\n",
    "generators.Var_Cost = zeros(Float64, nrow(generators))\n",
    "\n",
    "for g in 1:nrow(generators)\n",
    "    if generators.Fuel[g] == \"DR_Virtual\"\n",
    "        # DR resource: cost is just the strike price\n",
    "        generators.Var_Cost[g] = generators.Var_OM_cost_per_MWh[g]\n",
    "    else\n",
    "        # Normal generators: Fuel cost × Heat rate + VOM\n",
    "        fuel_cost = fuels[fuels.Fuel .== generators.Fuel[g], :Cost_per_MMBtu][1]\n",
    "        generators.Var_Cost[g] = generators.Var_OM_cost_per_MWh[g] + \n",
    "                                 fuel_cost * generators.Heat_rate_MMBTU_per_MWh[g]\n",
    "    end\n",
    "end\n",
    "\n",
    "# Define sets\n",
    "G = generators.R_ID  # All generators (including DR)\n",
    "S = convert(Array{Int64}, collect(skipmissing(demand_inputs.Demand_segment)))\n",
    "Z = convert(Array{Int64}, 1:3)  # Zones\n",
    "\n",
    "# Network/Transmission\n",
    "lines = select(network[1:2, :], :Network_lines, :z1, :z2, :z3, :Line_Max_Flow_MW, \n",
    "               :Line_Reinforcement_Cost_per_MW_yr)\n",
    "lines.Line_Fixed_Cost_per_MW_yr = lines.Line_Reinforcement_Cost_per_MW_yr ./ 20\n",
    "L = convert(Array{Int64}, lines.Network_lines)\n",
    "\n",
    "# NSE segments\n",
    "VOLL = demand_inputs.Voll[1]\n",
    "nse = DataFrame(\n",
    "    Segment = S,\n",
    "    NSE_Cost = VOLL .* collect(skipmissing(demand_inputs.Cost_of_demand_curtailment_perMW)),\n",
    "    NSE_Max = collect(skipmissing(demand_inputs.Max_demand_curtailment))\n",
    ")\n",
    "\n",
    "# Generator subsets\n",
    "STOR = intersect(generators.R_ID[generators.STOR .>= 1], G)\n",
    "NEW = intersect(generators.R_ID[generators.New_Build .== 1], G)\n",
    "OLD = intersect(generators.R_ID[.!(generators.New_Build .== 1)], G)\n",
    "THERM = intersect(generators.R_ID[generators.THERM .>= 1], G)\n",
    "\n",
    "println(\"\\nGenerator subsets:\")\n",
    "println(\"  Total resources (G): $(length(G))\")\n",
    "println(\"  Storage (STOR): $(length(STOR))\")\n",
    "println(\"  New-build candidates (NEW): $(length(NEW))\")\n",
    "println(\"  Existing units (OLD): $(length(OLD))\")\n",
    "println(\"  Thermal units (THERM): $(length(THERM))\")\n",
    "\n",
    "# Sync variability columns with generator IDs\n",
    "num_original_gens = ncol(variability)\n",
    "original_ids = generators.R_ID[1:num_original_gens]\n",
    "rename!(variability, Symbol.(original_ids))\n",
    "\n",
    "# Add DR availability\n",
    "if \"DataCenter_DR\" !in(names(variability))\n",
    "    variability[!, \"DataCenter_DR\"] .= 1.0\n",
    "end\n",
    "\n",
    "# Create generator lookup dictionary\n",
    "gen_lookup = Dict(row.R_ID => row for row in eachrow(generators))\n",
    "\n",
    "println(\"Pre-processing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimization Model Formulation\n",
    "\n",
    "### Model Structure\n",
    "\n",
    "**Decision Variables:**\n",
    "- Capacity: New builds, retirements, total capacity (generation, storage, transmission)\n",
    "- Operations: Hourly generation, charging, state-of-charge, line flows\n",
    "- Reliability: Non-served energy by segment and zone\n",
    "\n",
    "**Objective:**\n",
    "Minimize total annualized system cost ($ASC = Investment + OM_F + OM_V + NSE$)\n",
    "\n",
    "**Constraints:**\n",
    "- Energy balance (nodal)\n",
    "- Generator capacity limits (renewable availability)\n",
    "- Storage energy and power limits\n",
    "- Transmission flow limits\n",
    "- Ramping constraints (optional)\n",
    "- Time-coupling (storage SOC evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimization model...\n",
      "\n",
      "✓ Model initialized with HiGHS solver\n",
      "  Time limit: 600 seconds\n",
      "  Threads: 4\n",
      "\n",
      "✓ Decision variables created\n",
      "\n",
      "Adding constraints...\n",
      "  ✓ Demand balance (26280 constraints)\n",
      "  ✓ Capacity accounting (56 constraints)\n",
      "  ✓ Generation limits (490560 constraints)\n",
      "  ✓ Storage constraints (52566 constraints)\n",
      "  ✓ Transmission constraints (35042 constraints)\n",
      "  ✓ Ramping constraints (350360 constraints)\n",
      "  ✓ Storage SOC evolution (26277 constraints)\n",
      "\n",
      "✓ Objective function formulated\n",
      "\n",
      "════════════════════════════════════════════════════════════\n",
      "MODEL STATISTICS\n",
      "════════════════════════════════════════════════════════════\n",
      "Variables: 613322\n",
      "Constraints: 1576964\n",
      "════════════════════════════════════════════════════════════\n"
     ]
    }
   ],
   "source": [
    "println(\"Building optimization model\")\n",
    "\n",
    "# Initialize model\n",
    "Expansion_Model = Model(HiGHS.Optimizer)\n",
    "\n",
    "# Solver settings for large problems\n",
    "set_optimizer_attribute(Expansion_Model, \"time_limit\", 3000.0)  # 10 min timeout\n",
    "set_optimizer_attribute(Expansion_Model, \"threads\", 4)  # Use parallel threads\n",
    "\n",
    "println(\"Model initialized\")\n",
    "println(\"  Time limit: 3000 seconds\")\n",
    "println(\"  Threads: 4\\n\")\n",
    "\n",
    "# Decision Variables\n",
    "@variables(Expansion_Model, begin\n",
    "    # Capacity variables\n",
    "    vCAP[g in G] >= 0          # Total capacity (MW)\n",
    "    vNEW_CAP[g in NEW] >= 0    # New capacity built (MW)\n",
    "    vRET_CAP[g in OLD] >= 0    # Retired capacity (MW)\n",
    "    \n",
    "    # Storage energy capacity\n",
    "    vE_CAP[g in STOR] >= 0     # Total energy capacity (MWh)\n",
    "    vNEW_E_CAP[g in intersect(STOR, NEW)] >= 0\n",
    "    vRET_E_CAP[g in intersect(STOR, OLD)] >= 0\n",
    "    \n",
    "    # Transmission capacity\n",
    "    vT_CAP[l in L] >= 0       # Total line capacity (MW)\n",
    "    vNEW_T_CAP[l in L] >= 0   # New transmission capacity (MW)\n",
    "    \n",
    "    # Operational variables\n",
    "    vGEN[T, G] >= 0         # Hourly generation (MW)\n",
    "    vCHARGE[T, STOR] >= 0   # Hourly charging (MW)\n",
    "    vSOC[T, STOR] >= 0      # State of charge (MWh)\n",
    "    vNSE[T, S, Z] >= 0      # NSE (MW)\n",
    "    vFLOW[T, L]             # Line flows (MW)\n",
    "end)\n",
    "\n",
    "println(\"Created decision variables\")\n",
    "\n",
    "# Constraints\n",
    "println(\"\\nAdding constraints...\")\n",
    "\n",
    "# 1. Nodal Energy Balance\n",
    "@constraint(Expansion_Model, cDemandBalance[t in T, z in Z],\n",
    "    sum(vGEN[t, g] for g in intersect(generators[generators.zone .== z, :R_ID], G)) +\n",
    "    sum(vNSE[t, s, z] for s in S) - \n",
    "    sum(vCHARGE[t, g] for g in intersect(generators[generators.zone .== z, :R_ID], STOR)) -\n",
    "    demand[t, z] - \n",
    "    sum(lines[l, Symbol(string(\"z\", z))] * vFLOW[t, l] for l in L) == 0\n",
    ")\n",
    "\n",
    "println(\"  Demand balance ($(length(T) * length(Z)) constraints)\")\n",
    "\n",
    "# 2. Generator Capacity\n",
    "# Enforce maximum new build limits\n",
    "for g in NEW\n",
    "    if gen_lookup[g].Max_Cap_MW > 0\n",
    "        set_upper_bound(vNEW_CAP[g], gen_lookup[g].Max_Cap_MW)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Capacity Accounting\n",
    "@constraint(Expansion_Model, cCapOld[g in OLD],\n",
    "    vCAP[g] == gen_lookup[g].Existing_Cap_MW - vRET_CAP[g]\n",
    ")\n",
    "\n",
    "@constraint(Expansion_Model, cCapNew[g in NEW],\n",
    "    vCAP[g] == vNEW_CAP[g]\n",
    ")\n",
    "\n",
    "println(\"  Capacity accounting ($(length(G)) constraints)\")\n",
    "\n",
    "# 3. Generation Limits (includes renewable availability)\n",
    "@constraint(Expansion_Model, cMaxPower[t in T, g in G],\n",
    "    vGEN[t, g] <= variability[t, g] * vCAP[g]\n",
    ")\n",
    "\n",
    "println(\"  Generation limits ($(length(T) * length(G)) constraints)\")\n",
    "\n",
    "# 4. Storage\n",
    "if ENABLE_STORAGE\n",
    "    @constraint(Expansion_Model, cMaxCharge[t in T, g in STOR],\n",
    "        vCHARGE[t, g] <= vCAP[g]\n",
    "    )\n",
    "    \n",
    "    @constraint(Expansion_Model, cMaxSOC[t in T, g in STOR],\n",
    "        vSOC[t, g] <= vE_CAP[g]\n",
    "    )\n",
    "    \n",
    "    @constraint(Expansion_Model, cCapEnergyOld[g in intersect(STOR, OLD)],\n",
    "        vE_CAP[g] == gen_lookup[g].Existing_Cap_MWh - vRET_E_CAP[g]\n",
    "    )\n",
    "    \n",
    "    @constraint(Expansion_Model, cCapEnergyNew[g in intersect(STOR, NEW)],\n",
    "        vE_CAP[g] == vNEW_E_CAP[g]\n",
    "    )\n",
    "    \n",
    "    println(\"  Storage constraints ($(2*length(T)*length(STOR) + 2*length(STOR)) constraints)\")\n",
    "end\n",
    "\n",
    "# 5. Tranmission\n",
    "@constraint(Expansion_Model, cTransCap[l in L],\n",
    "    vT_CAP[l] == lines.Line_Max_Flow_MW[l] + (ENABLE_TRANSMISSION_EXPANSION ? vNEW_T_CAP[l] : 0)\n",
    ")\n",
    "\n",
    "@constraint(Expansion_Model, cMaxFlow[t in T, l in L],\n",
    "    vFLOW[t, l] <= vT_CAP[l]\n",
    ")\n",
    "\n",
    "@constraint(Expansion_Model, cMinFlow[t in T, l in L],\n",
    "    vFLOW[t, l] >= -vT_CAP[l]\n",
    ")\n",
    "\n",
    "println(\"  Transmission constraints ($(length(L) + 2*length(T)*length(L)) constraints)\")\n",
    "\n",
    "# 6. TIme-Coupling\n",
    "STARTS = 1:hours_per_period:maximum(T)\n",
    "INTERIORS = setdiff(T, STARTS)\n",
    "\n",
    "# Ramping\n",
    "if ENABLE_RAMPING\n",
    "    @constraint(Expansion_Model, cRampUp[t in INTERIORS, g in THERM],\n",
    "        vGEN[t, g] - vGEN[t-1, g] <= gen_lookup[g].Ramp_Up_percentage * vCAP[g]\n",
    "    )\n",
    "    \n",
    "    @constraint(Expansion_Model, cRampDown[t in INTERIORS, g in THERM],\n",
    "        vGEN[t-1, g] - vGEN[t, g] <= gen_lookup[g].Ramp_Dn_percentage * vCAP[g]\n",
    "    )\n",
    "    \n",
    "    println(\"  Ramping constraints ($(2*length(INTERIORS)*length(THERM)) constraints)\")\n",
    "end\n",
    "\n",
    "# Storage SOC evolution\n",
    "if ENABLE_STORAGE\n",
    "    @constraint(Expansion_Model, cSOC[t in INTERIORS, g in STOR],\n",
    "        vSOC[t, g] == vSOC[t-1, g] + \n",
    "                      gen_lookup[g].Eff_up * vCHARGE[t, g] - \n",
    "                      vGEN[t, g] / gen_lookup[g].Eff_down\n",
    "    )\n",
    "    \n",
    "    println(\"  Storage SOC evolution ($(length(INTERIORS)*length(STOR)) constraints)\")\n",
    "end\n",
    "\n",
    "# Objective Function\n",
    "@objective(Expansion_Model, Min,\n",
    "    # Fixed O&M costs for all capacity\n",
    "    sum(gen_lookup[g].Fixed_OM_cost_per_MWyr * vCAP[g] for g in G) +\n",
    "    \n",
    "    # Investment costs for new capacity\n",
    "    sum(gen_lookup[g].Inv_cost_per_MWyr * vNEW_CAP[g] for g in NEW) +\n",
    "    \n",
    "    # Storage energy capacity costs\n",
    "    sum(gen_lookup[g].Fixed_OM_cost_per_MWhyr * vE_CAP[g] for g in STOR) +\n",
    "    sum(gen_lookup[g].Inv_cost_per_MWhyr * vNEW_E_CAP[g] for g in intersect(STOR, NEW)) +\n",
    "    \n",
    "    # Transmission costs\n",
    "    sum(lines.Line_Fixed_Cost_per_MW_yr[l] * vT_CAP[l] for l in L) +\n",
    "    (ENABLE_TRANSMISSION_EXPANSION ? \n",
    "        sum(lines.Line_Reinforcement_Cost_per_MW_yr[l] * vNEW_T_CAP[l] for l in L) : 0) +\n",
    "    \n",
    "    # Variable operating costs (fuel + VOM) - annualized\n",
    "    sum(sample_weight[t] * gen_lookup[g].Var_Cost * vGEN[t, g] for t in T, g in G) +\n",
    "    \n",
    "    # NSE penalty\n",
    "    sum(sample_weight[t] * nse.NSE_Cost[s] * vNSE[t, s, z] for t in T, s in S, z in Z)\n",
    ")\n",
    "\n",
    "println(\"\\nObjective function formulated\")\n",
    "println(\"Model Statistics\")\n",
    "println(\"═\" ^ 25)\n",
    "println(\"Variables: $(num_variables(Expansion_Model))\")\n",
    "println(\"Constraints: $(num_constraints(Expansion_Model, count_variable_in_set_constraints=true))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Solve Model\n",
    "\n",
    "This cell solves the capacity expansion optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "════════════════════════════════════════════════════════════\n",
      "SOLVING OPTIMIZATION PROBLEM\n",
      "════════════════════════════════════════════════════════════\n",
      "This may take several minutes for the full annual model...\n",
      "\n",
      "Running HiGHS 1.11.0 (git hash: 364c83a51e): Copyright (c) 2025 HiGHS under MIT licence terms\n",
      "LP   has 981138 rows; 613322 cols; 2869523 nonzeros\n",
      "Coefficient ranges:\n",
      "  Matrix [1e-04, 4e+00]\n",
      "  Cost   [1e+01, 9e+05]\n",
      "  Bound  [8e+02, 9e+04]\n",
      "  RHS    [1e+01, 9e+04]\n",
      "Presolving model\n",
      "924770 rows, 565713 cols, 2756787 nonzeros  2s\n",
      "Dependent equations search running on 52557 equations with time limit of 6.00s\n",
      "Dependent equations search removed 0 rows and 0 nonzeros in 0.06s (limit = 6.00s)\n",
      "924770 rows, 539433 cols, 2730507 nonzeros  5s\n",
      "Presolve : Reductions: rows 924770(-56368); columns 539433(-73889); elements 2730507(-139016)\n",
      "Solving the presolved LP\n",
      "Using EKK dual simplex solver - serial\n",
      "  Iteration        Objective     Infeasibilities num(sum)\n",
      "          0     1.1539874499e+07 Pr: 26280(1.52668e+08); Du: 0(7.83961e-09) 10s\n",
      "       7486     2.4346835048e+08 Pr: 25988(1.46352e+08); Du: 0(5.07387e-07) 16s\n",
      "      14831     5.5599887398e+08 Pr: 25368(1.31662e+08); Du: 0(1.28458e-06) 21s\n",
      "      28631     9.0063445740e+08 Pr: 24549(5.21538e+07); Du: 0(2.72349e-06) 26s\n",
      "      41237     1.4795637004e+09 Pr: 24437(5.91051e+07); Du: 0(3.25483e-06) 32s\n",
      "      48536     1.6711510774e+09 Pr: 23542(1.12139e+08); Du: 0(5.06337e-06) 38s\n",
      "      50319     1.6724391170e+09 Pr: 22804(1.16439e+08); Du: 0(5.58057e-06) 43s\n",
      "      52038     1.6729479056e+09 Pr: 21929(1.40793e+08); Du: 0(6.59841e-06) 49s\n",
      "      54170     1.6729482255e+09 Pr: 20737(1.25277e+08); Du: 0(8.13284e-06) 55s\n",
      "      57605     1.6742216506e+09 Pr: 18104(6.78527e+07); Du: 0(1.29898e-05) 65s\n",
      "      58987     1.7019692319e+09 Pr: 18068(5.67332e+07); Du: 0(1.25856e-05) 70s\n",
      "      60612     1.7580969075e+09 Pr: 18013(5.53673e+07); Du: 0(1.28762e-05) 76s\n",
      "      62184     1.7927433392e+09 Pr: 18026(6.25538e+07); Du: 0(1.21074e-05) 81s\n",
      "      64707     1.8707862474e+09 Pr: 28734(1.13249e+08); Du: 0(1.19313e-05) 88s\n",
      "      68913     2.0322929926e+09 Pr: 18691(1.23946e+08); Du: 0(1.14033e-05) 95s\n",
      "      71662     2.1342108109e+09 Pr: 29223(1.26441e+08); Du: 0(1.10226e-05) 101s\n",
      "      75713     2.3240881824e+09 Pr: 27265(8.58664e+07); Du: 0(1.16645e-05) 108s\n",
      "      78336     2.3942153023e+09 Pr: 18325(7.3112e+07); Du: 0(1.18652e-05) 114s\n",
      "      81378     2.4680455963e+09 Pr: 18681(1.14538e+08); Du: 0(1.17414e-05) 120s\n",
      "      86028     2.6891919865e+09 Pr: 28791(1.38313e+08); Du: 0(1.13811e-05) 126s\n",
      "      88178     2.8311129591e+09 Pr: 20658(3.17689e+08); Du: 0(1.11509e-05) 134s\n",
      "      90570     2.9449908627e+09 Pr: 54782(6.86414e+08); Du: 0(1.09957e-05) 143s\n",
      "      91719     3.0057411242e+09 Pr: 19964(1.92111e+08); Du: 0(1.10024e-05) 148s\n",
      "      94468     3.0985096933e+09 Pr: 22830(1.0562e+08); Du: 0(1.09037e-05) 157s\n",
      "      95630     3.1826966298e+09 Pr: 40510(4.66984e+08); Du: 0(1.07345e-05) 162s\n",
      "      98951     3.3127198560e+09 Pr: 19630(6.54453e+07); Du: 0(1.06167e-05) 169s\n",
      "     101840     3.4423156795e+09 Pr: 20102(9.65471e+07); Du: 0(1.07605e-05) 175s\n",
      "     104355     3.5345601996e+09 Pr: 20787(6.34396e+07); Du: 0(1.14862e-05) 190s\n",
      "     105125     3.5686149902e+09 Pr: 53172(1.04654e+09); Du: 0(1.13879e-05) 196s\n",
      "     106175     3.6221267658e+09 Pr: 33241(2.11163e+08); Du: 0(1.13366e-05) 203s\n",
      "     107322     3.6683060756e+09 Pr: 24458(3.09154e+08); Du: 0(1.17514e-05) 210s\n",
      "     108841     3.6758937090e+09 Pr: 35185(2.25378e+08); Du: 0(1.03796e-05) 215s\n",
      "     109855     3.7257878434e+09 Pr: 52178(1.08652e+09); Du: 0(1.03872e-05) 222s\n",
      "     112057     3.8276589513e+09 Pr: 24120(2.35533e+08); Du: 0(9.90986e-06) 232s\n",
      "     113221     3.8625677082e+09 Pr: 33691(2.00847e+08); Du: 0(9.87282e-06) 239s\n",
      "     114434     3.9107403622e+09 Pr: 43450(1.38095e+09); Du: 0(1.00795e-05) 246s\n",
      "     116488     3.9952773999e+09 Pr: 19791(1.5246e+08); Du: 0(9.69583e-06) 256s\n",
      "     118170     4.0021561885e+09 Pr: 19022(1.38485e+08); Du: 0(1.06959e-05) 266s\n",
      "     119484     4.0481388206e+09 Pr: 22853(1.60716e+08); Du: 0(1.07493e-05) 271s\n",
      "     121976     4.1314404263e+09 Pr: 53819(2.45642e+08); Du: 0(1.07423e-05) 281s\n",
      "     123189     4.1785579894e+09 Pr: 60038(9.65413e+08); Du: 0(1.09007e-05) 289s\n",
      "     124096     4.2186703680e+09 Pr: 30846(8.13594e+08); Du: 0(1.05811e-05) 297s\n",
      "     125228     4.2721481592e+09 Pr: 42437(8.75263e+08); Du: 0(1.02907e-05) 304s\n",
      "     126301     4.3067403114e+09 Pr: 34162(1.79682e+08); Du: 0(1.04549e-05) 311s\n",
      "     127396     4.3598124560e+09 Pr: 26373(1.73203e+08); Du: 0(9.88109e-06) 319s\n",
      "     128361     4.3953928015e+09 Pr: 64596(2.346e+09); Du: 0(1.03068e-05) 325s\n",
      "     129179     4.4181690470e+09 Pr: 56349(7.06466e+09); Du: 0(1.00594e-05) 331s\n",
      "     130149     4.4599776100e+09 Pr: 71860(1.13849e+09); Du: 0(1.03721e-05) 339s\n",
      "     130914     4.5215491747e+09 Pr: 54376(8.50864e+08); Du: 0(1.03049e-05) 346s\n",
      "     131758     4.5872621731e+09 Pr: 54118(2.48301e+08); Du: 0(1.03049e-05) 354s\n",
      "     133078     4.6060024619e+09 Pr: 65703(7.96947e+09); Du: 0(9.99219e-06) 361s\n",
      "     134180     4.6359718285e+09 Pr: 71585(1.15237e+10); Du: 0(1.01899e-05) 368s\n",
      "     134890     4.6737141440e+09 Pr: 34346(3.14343e+09); Du: 0(1.00851e-05) 373s\n",
      "     135846     4.7207490559e+09 Pr: 28806(1.84818e+09); Du: 0(1.00241e-05) 379s\n",
      "     136860     4.7882183648e+09 Pr: 32183(9.69421e+08); Du: 0(9.92911e-06) 387s\n",
      "     137567     4.8260679606e+09 Pr: 54376(1.93015e+09); Du: 0(9.88615e-06) 394s\n",
      "     138380     4.8564060462e+09 Pr: 43642(1.80071e+09); Du: 0(1.00438e-05) 401s\n",
      "     138946     4.8750133030e+09 Pr: 41083(1.37995e+10); Du: 0(1.00566e-05) 408s\n",
      "     139991     4.8907646836e+09 Pr: 47999(1.44414e+10); Du: 0(9.84246e-06) 417s\n",
      "     141434     4.8907786926e+09 Pr: 47993(1.46585e+10); Du: 0(9.83164e-06) 430s\n",
      "     142068     4.9794345895e+09 Pr: 46878(2.00065e+10); Du: 0(9.73312e-06) 438s\n",
      "     142662     4.9964173979e+09 Pr: 70835(1.08804e+10); Du: 0(9.63773e-06) 444s\n",
      "     143389     5.0447762348e+09 Pr: 34168(1.47763e+09); Du: 0(9.51506e-06) 453s\n",
      "     144585     5.0654600517e+09 Pr: 48892(2.06653e+09); Du: 0(9.41238e-06) 462s\n",
      "     145133     5.0981168063e+09 Pr: 35173(2.8816e+08); Du: 0(9.63621e-06) 468s\n",
      "     146082     5.1413786409e+09 Pr: 56548(5.90088e+09); Du: 0(9.80273e-06) 478s\n",
      "     146990     5.1886412819e+09 Pr: 64104(3.84583e+09); Du: 0(9.7725e-06) 485s\n",
      "     163112     5.3146758800e+09 Pr: 70618(2.40405e+11); Du: 0(1.00136e-05) 491s\n",
      "     167806     5.6030801935e+09 Pr: 53815(3.7793e+10); Du: 0(9.71755e-06) 498s\n",
      "     170794     5.8173387584e+09 Pr: 40071(5.06134e+08); Du: 0(9.69536e-06) 507s\n",
      "     173254     5.9334491396e+09 Pr: 48634(1.78431e+09); Du: 0(9.75701e-06) 517s\n",
      "     176288     6.0591483520e+09 Pr: 33005(2.68512e+09); Du: 0(9.6033e-06) 526s\n",
      "     178734     6.1535643593e+09 Pr: 83640(1.11603e+10); Du: 0(9.72853e-06) 536s\n",
      "     181759     6.2572719708e+09 Pr: 51957(6.23476e+10); Du: 0(9.58842e-06) 546s\n",
      "     183996     6.3157868930e+09 Pr: 68997(1.69623e+11); Du: 0(9.70968e-06) 551s\n",
      "     186086     6.3806717950e+09 Pr: 52526(1.07208e+09); Du: 0(9.73579e-06) 557s\n",
      "     187935     6.4435401289e+09 Pr: 96593(7.44102e+09); Du: 0(9.88665e-06) 567s\n",
      "     188759     6.4678872415e+09 Pr: 67747(1.20164e+10); Du: 0(9.8792e-06) 573s\n",
      "     189629     6.4952560634e+09 Pr: 59369(8.68571e+10); Du: 0(9.95327e-06) 580s\n",
      "     190741     6.5353939161e+09 Pr: 34501(3.44055e+08); Du: 0(9.92282e-06) 586s\n",
      "     191666     6.5764343105e+09 Pr: 74732(5.39591e+08); Du: 0(9.9155e-06) 593s\n",
      "     192550     6.6127907896e+09 Pr: 84158(2.1802e+09); Du: 0(9.9155e-06) 599s\n",
      "     192648     6.6169227292e+09 600s\n",
      "Model status        : Time limit reached\n",
      "Simplex   iterations: 192648\n",
      "Objective value     :  6.6164785898e+09\n",
      "HiGHS run time      :        600.32\n",
      "619.936182 seconds (19.22 M allocations: 1.162 GiB, 1.55% gc time, 0.07% compilation time: 81% of which was recompilation)\n",
      "\n",
      "════════════════════════════════════════════════════════════\n",
      "SOLUTION STATUS: TIME_LIMIT\n",
      "════════════════════════════════════════════════════════════\n",
      "⚠ Time limit reached. Solution may be suboptimal.\n"
     ]
    }
   ],
   "source": [
    "println(\"Solving Optimization Problem\")\n",
    "println(\"\\n\" * \"═\" ^ 60)\n",
    "\n",
    "@time optimize!(Expansion_Model)\n",
    "\n",
    "# Check solution status\n",
    "status = termination_status(Expansion_Model)\n",
    "println(\"Solution Status: \", status)\n",
    "println(\"═\" ^ 55)\n",
    "\n",
    "if status == MOI.OPTIMAL\n",
    "    println(\"Optimal solution found!\")\n",
    "    obj_value = objective_value(Expansion_Model)\n",
    "    println(\"\\nTotal System Cost: \\$$(round(obj_value / 1e9, digits=2)) billion/year\")\n",
    "elseif status == MOI.TIME_LIMIT\n",
    "    println(\"Exceeded time limit. Solution may be suboptimal.\")\n",
    "    if has_values(Expansion_Model)\n",
    "        obj_value = objective_value(Expansion_Model)\n",
    "        println(\"Best solution found: \\$$(round(obj_value / 1e9, digits=2)) billion/year\")\n",
    "    end\n",
    "else\n",
    "    println(\"Optimization failed or infeasible\")\n",
    "    println(\"Status: \", status)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Analysis - Data Center Performance\n",
    "\n",
    "### Key Metrics:\n",
    "- **Curtailment Frequency**: How often is the data center load reduced?\n",
    "- **Energy Shifted**: Total MWh of load curtailment (virtual generation)\n",
    "- **Capacity Credit**: Does flexibility reduce peak capacity needs?\n",
    "- **Economic Value**: Cost savings from demand response capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠ No solution available for analysis\n"
     ]
    }
   ],
   "source": [
    "if has_values(Expansion_Model)\n",
    "    println(\"Data Center Flexibility Results\")\n",
    "    println(\"═\" ^ 60)\n",
    "    \n",
    "    # Extract DR generation (curtailment)\n",
    "    dc_gen = value.(vGEN)[:, \"DataCenter_DR\"]\n",
    "    dc_gen_vec = [dc_gen[t] for t in T]\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    total_dc_curtailment_MWh = sum(sample_weight .* dc_gen_vec)\n",
    "    total_dc_hours_curtailed = count(x -> x > 1.0, dc_gen_vec)\n",
    "    max_curtailment_MW = maximum(dc_gen_vec)\n",
    "    avg_curtailment_MW = total_dc_curtailment_MWh / sum(sample_weight[dc_gen_vec .> 1.0])\n",
    "    \n",
    "    # Calculate curtailment percentage\n",
    "    total_possible_MWh = DATA_CENTER_MW * sum(sample_weight)\n",
    "    curtailment_pct = (total_dc_curtailment_MWh / total_possible_MWh) * 100\n",
    "    \n",
    "    println(\"\\nConfiguration:\")\n",
    "    println(\"  Data Center Size: $(DATA_CENTER_MW) MW\")\n",
    "    println(\"  Location: Zone $(DATA_CENTER_ZONE)\")\n",
    "    println(\"  Strike Price: \\$$(STRIKE_PRICE)/MWh\")\n",
    "    \n",
    "    println(\"\\nCurtailment Statistics:\")\n",
    "    println(\"  Total Energy Curtailed: $(round(total_dc_curtailment_MWh, digits=0)) MWh/yr\")\n",
    "    println(\"  Curtailment as % of Load: $(round(curtailment_pct, digits=2))%\")\n",
    "    println(\"  Hours Curtailed: $(total_dc_hours_curtailed) hours ($(round(total_dc_hours_curtailed/length(T)*100, digits=2))%)\")\n",
    "    println(\"  Max Curtailment Event: $(round(max_curtailment_MW, digits=1)) MW\")\n",
    "    \n",
    "    if total_dc_hours_curtailed > 0\n",
    "        println(\"  Avg Curtailment When Active: $(round(avg_curtailment_MW, digits=1)) MW\")\n",
    "    end\n",
    "    \n",
    "    # Economic value\n",
    "    curtailment_cost = total_dc_curtailment_MWh * STRIKE_PRICE\n",
    "    println(\"\\nEconomic Impact:\")\n",
    "    println(\"  Annual Curtailment Payments: \\$$(round(curtailment_cost / 1e6, digits=2)) million/yr\")\n",
    "    \n",
    "    # Find top 10 curtailment events\n",
    "    curtailment_times = sortperm(dc_gen_vec, rev=true)[1:min(10, total_dc_hours_curtailed)]\n",
    "    \n",
    "    if total_dc_hours_curtailed > 0\n",
    "        println(\"\\nTop 10 Curtailment Events (Hour, MW):\")\n",
    "        for (i, t) in enumerate(curtailment_times)\n",
    "            if dc_gen_vec[t] > 1.0\n",
    "                println(@sprintf(\"  %2d. Hour %4d: %6.1f MW\", i, t, dc_gen_vec[t]))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "else\n",
    "    println(\"No solution available for analysis\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Analysis - Capacity Expansion\n",
    "\n",
    "Analyze what new generation, storage, and transmission capacity the model selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_values(Expansion_Model)\n",
    "    println(\"Capacity Expansion Results\")\n",
    "    println(\"═\" ^ 60)\n",
    "    \n",
    "    # New Generation Capacity\n",
    "    new_builds = DataFrame(\n",
    "        ID = NEW,\n",
    "        Resource = [gen_lookup[g].Resource for g in NEW],\n",
    "        Zone = [gen_lookup[g].zone for g in NEW],\n",
    "        New_MW = [value(vNEW_CAP[g]) for g in NEW],\n",
    "        Inv_Cost_M = [value(vNEW_CAP[g]) * gen_lookup[g].Inv_cost_per_MWyr / 1e6 for g in NEW]\n",
    "    )\n",
    "    \n",
    "    # Filter to significant builds (> 1 MW)\n",
    "    new_builds = filter(row -> row.New_MW > 1.0, new_builds)\n",
    "    sort!(new_builds, :New_MW, rev=true)\n",
    "    \n",
    "    if nrow(new_builds) > 0\n",
    "        println(\"\\nNew Generation Capacity:\")\n",
    "        println(\"  Total New Build: $(round(sum(new_builds.New_MW), digits=0)) MW\")\n",
    "        println(\"  Investment Cost: \\$$(round(sum(new_builds.Inv_Cost_M), digits=1)) million/yr\\n\")\n",
    "        show(new_builds, allrows=true, summary=false)\n",
    "        \n",
    "        # Summary by technology type\n",
    "        println(\"\\n\\nNew Capacity by Technology:\")\n",
    "        tech_summary = combine(groupby(new_builds, :Resource), :New_MW => sum => :Total_MW)\n",
    "        sort!(tech_summary, :Total_MW, rev=true)\n",
    "        for row in eachrow(tech_summary)\n",
    "            println(@sprintf(\"  %-30s: %8.0f MW\", row.Resource, row.Total_MW))\n",
    "        end\n",
    "        \n",
    "        # Summary by zone\n",
    "        println(\"\\nNew Capacity by Zone:\")\n",
    "        zone_summary = combine(groupby(new_builds, :Zone), :New_MW => sum => :Total_MW)\n",
    "        sort!(zone_summary, :Zone)\n",
    "        for row in eachrow(zone_summary)\n",
    "            println(@sprintf(\"  Zone %d: %8.0f MW\", row.Zone, row.Total_MW))\n",
    "        end\n",
    "    else\n",
    "        println(\"\\nNo new generation capacity built.\")\n",
    "    end\n",
    "    \n",
    "    # Retirements\n",
    "    retirements = DataFrame(\n",
    "        ID = OLD,\n",
    "        Resource = [gen_lookup[g].Resource for g in OLD],\n",
    "        Zone = [gen_lookup[g].zone for g in OLD],\n",
    "        Retired_MW = [value(vRET_CAP[g]) for g in OLD]\n",
    "    )\n",
    "    \n",
    "    retirements = filter(row -> row.Retired_MW > 1.0, retirements)\n",
    "    \n",
    "    if nrow(retirements) > 0\n",
    "        println(\"\\n\\nRetirements:\")\n",
    "        println(\"  Total Retired: $(round(sum(retirements.Retired_MW), digits=0)) MW\\n\")\n",
    "        show(retirements, allrows=true, summary=false)\n",
    "    else\n",
    "        println(\"\\n\\nNo existing capacity retired.\")\n",
    "    end\n",
    "    \n",
    "    # Storage\n",
    "    if ENABLE_STORAGE && length(STOR) > 0\n",
    "        stor_new = intersect(STOR, NEW)\n",
    "        if length(stor_new) > 0\n",
    "            storage_builds = DataFrame(\n",
    "                ID = stor_new,\n",
    "                Resource = [gen_lookup[g].Resource for g in stor_new],\n",
    "                Zone = [gen_lookup[g].zone for g in stor_new],\n",
    "                Power_MW = [value(vNEW_CAP[g]) for g in stor_new],\n",
    "                Energy_MWh = [value(vNEW_E_CAP[g]) for g in stor_new],\n",
    "                Duration_hrs = [value(vNEW_E_CAP[g]) / max(value(vNEW_CAP[g]), 0.001) for g in stor_new]\n",
    "            )\n",
    "            \n",
    "            storage_builds = filter(row -> row.Power_MW > 1.0, storage_builds)\n",
    "            \n",
    "            if nrow(storage_builds) > 0\n",
    "                println(\"\\n\\nNew Storage Capacity:\")\n",
    "                println(\"  Total Power: $(round(sum(storage_builds.Power_MW), digits=0)) MW\")\n",
    "                println(\"  Total Energy: $(round(sum(storage_builds.Energy_MWh), digits=0)) MWh\\n\")\n",
    "                show(storage_builds, allrows=true, summary=false)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Transmission\n",
    "    if ENABLE_TRANSMISSION_EXPANSION\n",
    "        trans_expansion = DataFrame(\n",
    "            Line = L,\n",
    "            Existing_MW = lines.Line_Max_Flow_MW,\n",
    "            New_MW = [value(vNEW_T_CAP[l]) for l in L],\n",
    "            Total_MW = [value(vT_CAP[l]) for l in L]\n",
    "        )\n",
    "        \n",
    "        trans_expansion = filter(row -> row.New_MW > 1.0, trans_expansion)\n",
    "        \n",
    "        if nrow(trans_expansion) > 0\n",
    "            println(\"\\n\\nTransmission Expansion:\")\n",
    "            show(trans_expansion, allrows=true, summary=false)\n",
    "        else\n",
    "            println(\"\\n\\nNo new transmission capacity built.\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. System-Level Metrics\n",
    "\n",
    "Calculate reliability, emissions, and cost breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_values(Expansion_Model)\n",
    "    println(\"System Performance Metrics\")\n",
    "    println(\"═\" ^ 60)\n",
    "    \n",
    "    # Reliability\n",
    "    nse_values = value.(vNSE)\n",
    "    total_nse = sum(sample_weight[t] * sum(nse_values[t, s, z] for s in S, z in Z) for t in T)\n",
    "    total_demand = sum(sample_weight .* [sum(demand[t, z] for z in Z) for t in T])\n",
    "    \n",
    "    println(\"\\nReliability:\")\n",
    "    println(\"  Total Demand Served: $(round(total_demand / 1e6, digits=1)) TWh/yr\")\n",
    "    println(\"  Non-Served Energy: $(round(total_nse, digits=0)) MWh/yr\")\n",
    "    if total_nse > 0\n",
    "        println(\"  Loss of Load Probability: $(round(total_nse / total_demand * 100, digits=4))%\")\n",
    "    else\n",
    "        println(\"  Perfect reliability (no unserved energy)\")\n",
    "    end\n",
    "    \n",
    "    # Generation Mix\n",
    "    gen_values = value.(vGEN)\n",
    "    gen_by_resource = Dict{String, Float64}()\n",
    "    \n",
    "    for g in G\n",
    "        resource_type = gen_lookup[g].Resource\n",
    "        annual_gen = sum(sample_weight[t] * gen_values[t, g] for t in T)\n",
    "        \n",
    "        if haskey(gen_by_resource, resource_type)\n",
    "            gen_by_resource[resource_type] += annual_gen\n",
    "        else\n",
    "            gen_by_resource[resource_type] = annual_gen\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    total_generation = sum(values(gen_by_resource))\n",
    "    \n",
    "    println(\"\\nGeneration Mix:\")\n",
    "    println(\"  Total Generation: $(round(total_generation / 1e6, digits=1)) TWh/yr\\n\")\n",
    "    \n",
    "    # Sort by generation amount\n",
    "    sorted_resources = sort(collect(gen_by_resource), by=x->x[2], rev=true)\n",
    "    \n",
    "    for (resource, gen) in sorted_resources\n",
    "        if gen > 100  # Only show resources with >100 MWh\n",
    "            pct = gen / total_generation * 100\n",
    "            println(@sprintf(\"  %-30s: %8.1f TWh (%5.2f%%)\", \n",
    "                             resource, gen/1e6, pct))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate renewable percentage\n",
    "    renewable_gen = sum(gen_by_resource[r] for r in keys(gen_by_resource) \n",
    "                       if occursin(\"solar\", lowercase(r)) || \n",
    "                          occursin(\"wind\", lowercase(r)) ||\n",
    "                          occursin(\"pv\", lowercase(r)))\n",
    "    \n",
    "    println(\"\\n  Renewable Penetration: $(round(renewable_gen / total_generation * 100, digits=1))%\")\n",
    "    \n",
    "    # Cost Breakdown\n",
    "    println(\"\\nCost Breakdown:\")\n",
    "    \n",
    "    # Calculate individual cost components\n",
    "    fixed_om_cost = sum(gen_lookup[g].Fixed_OM_cost_per_MWyr * value(vCAP[g]) for g in G)\n",
    "    inv_cost = sum(gen_lookup[g].Inv_cost_per_MWyr * value(vNEW_CAP[g]) for g in NEW)\n",
    "    \n",
    "    var_cost = sum(sample_weight[t] * gen_lookup[g].Var_Cost * gen_values[t, g] \n",
    "                  for t in T, g in G)\n",
    "    \n",
    "    nse_cost = sum(sample_weight[t] * nse.NSE_Cost[s] * nse_values[t, s, z] \n",
    "                  for t in T, s in S, z in Z)\n",
    "    \n",
    "    total_cost = objective_value(Expansion_Model)\n",
    "    \n",
    "    println(@sprintf(\"  Investment (Generation): \\$%6.1f million/yr (%4.1f%%)\",\n",
    "                     inv_cost/1e6, inv_cost/total_cost*100))\n",
    "    println(@sprintf(\"  Fixed O&M:              \\$%6.1f million/yr (%4.1f%%)\",\n",
    "                     fixed_om_cost/1e6, fixed_om_cost/total_cost*100))\n",
    "    println(@sprintf(\"  Variable O&M + Fuel:    \\$%6.1f million/yr (%4.1f%%)\",\n",
    "                     var_cost/1e6, var_cost/total_cost*100))\n",
    "    \n",
    "    if nse_cost > 0\n",
    "        println(@sprintf(\"  Unserved Energy:        \\$%6.1f million/yr (%4.1f%%)\",\n",
    "                         nse_cost/1e6, nse_cost/total_cost*100))\n",
    "    end\n",
    "    \n",
    "    println(@sprintf(\"\\n  Total System Cost:      \\$%6.1f billion/yr\",\n",
    "                     total_cost/1e9))\n",
    "    \n",
    "    # Average cost per MWh\n",
    "    avg_cost_per_mwh = total_cost / total_demand\n",
    "    println(@sprintf(\"  Average Cost:           \\$%6.2f/MWh\", avg_cost_per_mwh))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sensitivity Analysis (Optional)\n",
    "\n",
    "Run multiple scenarios with different strike prices to create a value curve for demand flexibility.\n",
    "\n",
    "**Warning:** This will solve the model multiple times and can take significant time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠ Sensitivity analysis disabled (set RUN_SENSITIVITY_ANALYSIS = true to enable)\n"
     ]
    }
   ],
   "source": [
    "if RUN_SENSITIVITY_ANALYSIS\n",
    "    println(\"Strike Price Sensitivity Analysis\")\n",
    "    println(\"═\" ^ 60)\n",
    "\n",
    "    # Define strike price sweep\n",
    "    strike_prices = [100.0, 200.0, 300.0, 500.0, 1000.0, 2000.0, 5000.0, 9000.0]\n",
    "\n",
    "    # Results storage\n",
    "    sensitivity_results = DataFrame(\n",
    "        StrikePrice = Float64[],\n",
    "        TotalCost = Float64[],\n",
    "        Curtailment_MWh = Float64[],\n",
    "        Curtailment_Pct = Float64[],\n",
    "        Curtailment_Hours = Int64[],\n",
    "        NewCapacity_MW = Float64[],\n",
    "        NewSolar_MW = Float64[],\n",
    "        NewGas_MW = Float64[],\n",
    "        NewStorage_MW = Float64[],\n",
    "        RenewablePct = Float64[],\n",
    "        SolveTime = Float64[],\n",
    "        Status = String[]\n",
    "    )\n",
    "\n",
    "    # Helper function to build and solve model\n",
    "    function solve_scenario(strike_price::Float64, gen_lookup_local, generators_local)\n",
    "        # Update DR resource cost\n",
    "        gen_lookup_local[\"DataCenter_DR\"].Var_Cost = strike_price\n",
    "\n",
    "        # Build model\n",
    "        model = Model(HiGHS.Optimizer)\n",
    "        set_optimizer_attribute(model, \"time_limit\", 600.0)\n",
    "        set_optimizer_attribute(model, \"threads\", 4)\n",
    "        set_optimizer_attribute(model, \"output_flag\", false)  # Suppress solver output\n",
    "\n",
    "        # Decision variables\n",
    "        @variables(model, begin\n",
    "            vCAP[g in G] >= 0\n",
    "            vNEW_CAP[g in NEW] >= 0\n",
    "            vRET_CAP[g in OLD] >= 0\n",
    "            vE_CAP[g in STOR] >= 0\n",
    "            vNEW_E_CAP[g in intersect(STOR, NEW)] >= 0\n",
    "            vRET_E_CAP[g in intersect(STOR, OLD)] >= 0\n",
    "            vT_CAP[l in L] >= 0\n",
    "            vNEW_T_CAP[l in L] >= 0\n",
    "            vGEN[T, G] >= 0\n",
    "            vCHARGE[T, STOR] >= 0\n",
    "            vSOC[T, STOR] >= 0\n",
    "            vNSE[T, S, Z] >= 0\n",
    "            vFLOW[T, L]\n",
    "        end)\n",
    "\n",
    "        # Constraints\n",
    "        # 1. Demand Balance\n",
    "        @constraint(model, cDemandBalance[t in T, z in Z],\n",
    "            sum(vGEN[t, g] for g in intersect(generators_local[generators_local.zone .== z, :R_ID], G)) +\n",
    "            sum(vNSE[t, s, z] for s in S) -\n",
    "            sum(vCHARGE[t, g] for g in intersect(generators_local[generators_local.zone .== z, :R_ID], STOR)) -\n",
    "            demand[t, z] -\n",
    "            sum(lines[l, Symbol(string(\"z\", z))] * vFLOW[t, l] for l in L) == 0\n",
    "        )\n",
    "\n",
    "        # 2. Capacity\n",
    "        for g in NEW\n",
    "            if gen_lookup_local[g].Max_Cap_MW > 0\n",
    "                set_upper_bound(vNEW_CAP[g], gen_lookup_local[g].Max_Cap_MW)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        @constraint(model, cCapOld[g in OLD],\n",
    "            vCAP[g] == gen_lookup_local[g].Existing_Cap_MW - vRET_CAP[g]\n",
    "        )\n",
    "\n",
    "        @constraint(model, cCapNew[g in NEW],\n",
    "            vCAP[g] == vNEW_CAP[g]\n",
    "        )\n",
    "\n",
    "        # 3. Generation\n",
    "        @constraint(model, cMaxPower[t in T, g in G],\n",
    "            vGEN[t, g] <= variability[t, g] * vCAP[g]\n",
    "        )\n",
    "\n",
    "        # 4. Storage\n",
    "        if ENABLE_STORAGE\n",
    "            @constraint(model, cMaxCharge[t in T, g in STOR],\n",
    "                vCHARGE[t, g] <= vCAP[g]\n",
    "            )\n",
    "\n",
    "            @constraint(model, cMaxSOC[t in T, g in STOR],\n",
    "                vSOC[t, g] <= vE_CAP[g]\n",
    "            )\n",
    "\n",
    "            @constraint(model, cCapEnergyOld[g in intersect(STOR, OLD)],\n",
    "                vE_CAP[g] == gen_lookup_local[g].Existing_Cap_MWh - vRET_E_CAP[g]\n",
    "            )\n",
    "\n",
    "            @constraint(model, cCapEnergyNew[g in intersect(STOR, NEW)],\n",
    "                vE_CAP[g] == vNEW_E_CAP[g]\n",
    "            )\n",
    "        end\n",
    "\n",
    "        # 5. Transmission\n",
    "        @constraint(model, cTransCap[l in L],\n",
    "            vT_CAP[l] == lines.Line_Max_Flow_MW[l] + (ENABLE_TRANSMISSION_EXPANSION ? vNEW_T_CAP[l] : 0)\n",
    "        )\n",
    "\n",
    "        @constraint(model, cMaxFlow[t in T, l in L],\n",
    "            vFLOW[t, l] <= vT_CAP[l]\n",
    "        )\n",
    "\n",
    "        @constraint(model, cMinFlow[t in T, l in L],\n",
    "            vFLOW[t, l] >= -vT_CAP[l]\n",
    "        )\n",
    "\n",
    "        # 6. Time coupling\n",
    "        if ENABLE_RAMPING\n",
    "            @constraint(model, cRampUp[t in INTERIORS, g in THERM],\n",
    "                vGEN[t, g] - vGEN[t-1, g] <= gen_lookup_local[g].Ramp_Up_percentage * vCAP[g]\n",
    "            )\n",
    "\n",
    "            @constraint(model, cRampDown[t in INTERIORS, g in THERM],\n",
    "                vGEN[t-1, g] - vGEN[t, g] <= gen_lookup_local[g].Ramp_Dn_percentage * vCAP[g]\n",
    "            )\n",
    "        end\n",
    "\n",
    "        if ENABLE_STORAGE\n",
    "            @constraint(model, cSOC[t in INTERIORS, g in STOR],\n",
    "                vSOC[t, g] == vSOC[t-1, g] +\n",
    "                              gen_lookup_local[g].Eff_up * vCHARGE[t, g] -\n",
    "                              vGEN[t, g] / gen_lookup_local[g].Eff_down\n",
    "            )\n",
    "        end\n",
    "\n",
    "        # Objective\n",
    "        @objective(model, Min,\n",
    "            sum(gen_lookup_local[g].Fixed_OM_cost_per_MWyr * vCAP[g] for g in G) +\n",
    "            sum(gen_lookup_local[g].Inv_cost_per_MWyr * vNEW_CAP[g] for g in NEW) +\n",
    "            sum(gen_lookup_local[g].Fixed_OM_cost_per_MWhyr * vE_CAP[g] for g in STOR) +\n",
    "            sum(gen_lookup_local[g].Inv_cost_per_MWhyr * vNEW_E_CAP[g] for g in intersect(STOR, NEW)) +\n",
    "            sum(lines.Line_Fixed_Cost_per_MW_yr[l] * vT_CAP[l] for l in L) +\n",
    "            (ENABLE_TRANSMISSION_EXPANSION ?\n",
    "                sum(lines.Line_Reinforcement_Cost_per_MW_yr[l] * vNEW_T_CAP[l] for l in L) : 0) +\n",
    "            sum(sample_weight[t] * gen_lookup_local[g].Var_Cost * vGEN[t, g] for t in T, g in G) +\n",
    "            sum(sample_weight[t] * nse.NSE_Cost[s] * vNSE[t, s, z] for t in T, s in S, z in Z)\n",
    "        )\n",
    "\n",
    "        # Solve\n",
    "        solve_start = time()\n",
    "        optimize!(model)\n",
    "        solve_time = time() - solve_start\n",
    "\n",
    "        return model, solve_time\n",
    "    end\n",
    "\n",
    "    # Run sensitivity analysis\n",
    "    for (idx, sp) in enumerate(strike_prices)\n",
    "        println(\"[$idx/$(length(strike_prices))] Testing Strike Price: \\$$(sp)/MWh...\")\n",
    "\n",
    "        # Create deep copy of gen_lookup for this scenario\n",
    "        gen_lookup_scenario = deepcopy(gen_lookup)\n",
    "        generators_scenario = deepcopy(generators)\n",
    "\n",
    "        try\n",
    "            # Solve scenario\n",
    "            scenario_model, solve_time = solve_scenario(sp, gen_lookup_scenario, generators_scenario)\n",
    "\n",
    "            # Check solution status\n",
    "            status = termination_status(scenario_model)\n",
    "\n",
    "            if has_values(scenario_model)\n",
    "                # Extract results\n",
    "                total_cost = objective_value(scenario_model)\n",
    "\n",
    "                # Curtailment metrics\n",
    "                dc_gen_vec = [value(scenario_model[:vGEN][t, \"DataCenter_DR\"]) for t in T]\n",
    "                curtailment_mwh = sum(sample_weight .* dc_gen_vec)\n",
    "                curtailment_pct = (curtailment_mwh / (DATA_CENTER_MW * sum(sample_weight))) * 100\n",
    "                curtailment_hours = count(x -> x > 1.0, dc_gen_vec)\n",
    "\n",
    "                # Capacity expansion metrics\n",
    "                new_cap_total = sum(value(scenario_model[:vNEW_CAP][g]) for g in NEW)\n",
    "\n",
    "                # New capacity by technology\n",
    "                new_solar = 0.0\n",
    "                new_gas = 0.0\n",
    "                new_storage = 0.0\n",
    "\n",
    "                for g in NEW\n",
    "                    cap = value(scenario_model[:vNEW_CAP][g])\n",
    "                    resource = gen_lookup_scenario[g].Resource\n",
    "\n",
    "                    if occursin(\"pv\", lowercase(resource)) || occursin(\"solar\", lowercase(resource))\n",
    "                        new_solar += cap\n",
    "                    elseif occursin(\"gas\", lowercase(resource))\n",
    "                        new_gas += cap\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # Storage\n",
    "                if ENABLE_STORAGE\n",
    "                    for g in intersect(STOR, NEW)\n",
    "                        new_storage += value(scenario_model[:vNEW_CAP][g])\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                # Generation mix for renewable percentage\n",
    "                gen_by_res = Dict{String, Float64}()\n",
    "                for g in G\n",
    "                    resource = gen_lookup_scenario[g].Resource\n",
    "                    annual_gen = sum(sample_weight[t] * value(scenario_model[:vGEN][t, g]) for t in T)\n",
    "\n",
    "                    if haskey(gen_by_res, resource)\n",
    "                        gen_by_res[resource] += annual_gen\n",
    "                    else\n",
    "                        gen_by_res[resource] = annual_gen\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                total_gen = sum(values(gen_by_res))\n",
    "                renewable_gen = sum(gen_by_res[r] for r in keys(gen_by_res)\n",
    "                                   if occursin(\"solar\", lowercase(r)) ||\n",
    "                                      occursin(\"wind\", lowercase(r)) ||\n",
    "                                      occursin(\"pv\", lowercase(r)))\n",
    "                renewable_pct = (renewable_gen / total_gen) * 100\n",
    "\n",
    "                # Store results\n",
    "                push!(sensitivity_results, (\n",
    "                    StrikePrice = sp,\n",
    "                    TotalCost = total_cost,\n",
    "                    Curtailment_MWh = curtailment_mwh,\n",
    "                    Curtailment_Pct = curtailment_pct,\n",
    "                    Curtailment_Hours = curtailment_hours,\n",
    "                    NewCapacity_MW = new_cap_total,\n",
    "                    NewSolar_MW = new_solar,\n",
    "                    NewGas_MW = new_gas,\n",
    "                    NewStorage_MW = new_storage,\n",
    "                    RenewablePct = renewable_pct,\n",
    "                    SolveTime = solve_time,\n",
    "                    Status = string(status)\n",
    "                ))\n",
    "\n",
    "                println(\"  Solved in $(round(solve_time, digits=1))s - Cost: \\$$(round(total_cost/1e9, digits=2))B - Curtailment: $(round(curtailment_mwh, digits=0)) MWh\")\n",
    "            else\n",
    "                println(\"  No solution found - Status: $(status)\")\n",
    "                push!(sensitivity_results, (\n",
    "                    StrikePrice = sp,\n",
    "                    TotalCost = NaN,\n",
    "                    Curtailment_MWh = NaN,\n",
    "                    Curtailment_Pct = NaN,\n",
    "                    Curtailment_Hours = 0,\n",
    "                    NewCapacity_MW = NaN,\n",
    "                    NewSolar_MW = NaN,\n",
    "                    NewGas_MW = NaN,\n",
    "                    NewStorage_MW = NaN,\n",
    "                    RenewablePct = NaN,\n",
    "                    SolveTime = solve_time,\n",
    "                    Status = string(status)\n",
    "                ))\n",
    "            end\n",
    "        catch e\n",
    "            println(\"  Error: $(e)\")\n",
    "            push!(sensitivity_results, (\n",
    "                StrikePrice = sp,\n",
    "                TotalCost = NaN,\n",
    "                Curtailment_MWh = NaN,\n",
    "                Curtailment_Pct = NaN,\n",
    "                Curtailment_Hours = 0,\n",
    "                NewCapacity_MW = NaN,\n",
    "                NewSolar_MW = NaN,\n",
    "                NewGas_MW = NaN,\n",
    "                NewStorage_MW = NaN,\n",
    "                RenewablePct = NaN,\n",
    "                SolveTime = 0.0,\n",
    "                Status = \"ERROR\"\n",
    "            ))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Display results\n",
    "    println(\"Sensitivity Analysis Results\")\n",
    "    println(\"═\" ^ 60)\n",
    "    show(sensitivity_results, allrows=true)\n",
    "\n",
    "    # Export results\n",
    "    mkpath(\"results\")\n",
    "    CSV.write(\"results/sensitivity_analysis.csv\", sensitivity_results)\n",
    "    println(\"\\n\\n Results exported to results/sensitivity_analysis.csv\")\n",
    "\n",
    "    # Summary\n",
    "    println(\"Key Insights\")\n",
    "    println(\"─\" ^ 60)\n",
    "\n",
    "    valid_results = filter(row -> !isnan(row.TotalCost), sensitivity_results)\n",
    "\n",
    "    if nrow(valid_results) > 0\n",
    "        # Find optimal strike price range\n",
    "        min_cost_row = valid_results[argmin(valid_results.TotalCost), :]\n",
    "        max_curtail_row = valid_results[argmax(valid_results.Curtailment_MWh), :]\n",
    "\n",
    "        println(\"Lowest System Cost:\")\n",
    "        println(\"  Strike Price: \\$$(min_cost_row.StrikePrice)/MWh\")\n",
    "        println(\"  Total Cost: \\$$(round(min_cost_row.TotalCost/1e9, digits=2)) billion/yr\")\n",
    "        println(\"  Curtailment: $(round(min_cost_row.Curtailment_MWh, digits=0)) MWh/yr ($(round(min_cost_row.Curtailment_Pct, digits=2))%)\")\n",
    "\n",
    "        println(\"\\nMaximum Flexibility Utilization:\")\n",
    "        println(\"  Strike Price: \\$$(max_curtail_row.StrikePrice)/MWh\")\n",
    "        println(\"  Curtailment: $(round(max_curtail_row.Curtailment_MWh, digits=0)) MWh/yr ($(round(max_curtail_row.Curtailment_Pct, digits=2))%)\")\n",
    "        println(\"  Curtailment Hours: $(max_curtail_row.Curtailment_Hours)\")\n",
    "\n",
    "        # Capacity value analysis\n",
    "        if nrow(valid_results) >= 2\n",
    "            firm_cost = valid_results[valid_results.StrikePrice .== maximum(valid_results.StrikePrice), :TotalCost][1]\n",
    "            flex_cost = valid_results[valid_results.StrikePrice .== minimum(valid_results.StrikePrice), :TotalCost][1]\n",
    "            savings = firm_cost - flex_cost\n",
    "\n",
    "            println(\"\\nCapacity Value of Flexibility:\")\n",
    "            println(\"  System cost w/ firm load (\\$9000/MWh): \\$$(round(firm_cost/1e9, digits=2))B/yr\")\n",
    "            println(\"  System cost w/ flexible load (\\$$(minimum(valid_results.StrikePrice))/MWh): \\$$(round(flex_cost/1e9, digits=2))B/yr\")\n",
    "            println(\"  Annual savings: \\$$(round(savings/1e6, digits=1)) million/yr\")\n",
    "        end\n",
    "    end\n",
    "else\n",
    "    println(\"\\n Sensitivity analysis disabled (set RUN_SENSITIVITY_ANALYSIS = true to enable)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Results (Optional)\n",
    "\n",
    "Export detailed results to CSV files for further analysis in Excel, Python, or visualization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠ Result export disabled (set SAVE_HOURLY_RESULTS = true to enable)\n"
     ]
    }
   ],
   "source": [
    "if has_values(Expansion_Model) && SAVE_HOURLY_RESULTS\n",
    "    println(\"\\nExporting results to CSV files...\")\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = \"results\"\n",
    "    mkpath(results_dir)\n",
    "    \n",
    "    # 1. Export capacity expansion decisions\n",
    "    capacity_results = DataFrame(\n",
    "        Generator = G,\n",
    "        Resource = [gen_lookup[g].Resource for g in G],\n",
    "        Zone = [gen_lookup[g].zone for g in G],\n",
    "        Existing_MW = [gen_lookup[g].Existing_Cap_MW for g in G],\n",
    "        Total_MW = [value(vCAP[g]) for g in G],\n",
    "        New_MW = [g in NEW ? value(vNEW_CAP[g]) : 0.0 for g in G],\n",
    "        Retired_MW = [g in OLD ? value(vRET_CAP[g]) : 0.0 for g in G]\n",
    "    )\n",
    "    \n",
    "    CSV.write(joinpath(results_dir, \"capacity_expansion.csv\"), capacity_results)\n",
    "    println(\"  Saved capacity_expansion.csv\")\n",
    "    \n",
    "    # 2. Export hourly generation (WARNING: Large file!)\n",
    "    gen_hourly = DataFrame(\n",
    "        Hour = repeat(T, outer=length(G)),\n",
    "        Generator = repeat(G, inner=length(T)),\n",
    "        Generation_MW = vec([value(vGEN[t, g]) for t in T, g in G])\n",
    "    )\n",
    "    \n",
    "    CSV.write(joinpath(results_dir, \"hourly_generation.csv\"), gen_hourly)\n",
    "    println(\"  Saved hourly_generation.csv\")\n",
    "    \n",
    "    # 3. Export data center curtailment events\n",
    "    dc_gen_vec = [value(vGEN[t, \"DataCenter_DR\"]) for t in T]\n",
    "    curtailment_events = DataFrame(\n",
    "        Hour = T,\n",
    "        Curtailment_MW = dc_gen_vec,\n",
    "        Demand_Z1 = demand.Load_MW_z1,\n",
    "        Demand_Z2 = demand.Load_MW_z2,\n",
    "        Demand_Z3 = demand.Load_MW_z3\n",
    "    )\n",
    "    \n",
    "    CSV.write(joinpath(results_dir, \"datacenter_curtailment.csv\"), curtailment_events)\n",
    "    println(\"  Saved datacenter_curtailment.csv\")\n",
    "    \n",
    "    # 4. Export summary statistics\n",
    "    summary = DataFrame(\n",
    "        Metric = [\n",
    "            \"Total_Cost_per_yr\",\n",
    "            \"DataCenter_Size_MW\",\n",
    "            \"DataCenter_Zone\",\n",
    "            \"Strike_Price_per_MWh\",\n",
    "            \"Curtailment_MWh_per_yr\",\n",
    "            \"Curtailment_Hours\",\n",
    "            \"New_Capacity_MW\",\n",
    "            \"Total_Generation_TWh\"\n",
    "        ],\n",
    "        Value = [\n",
    "            objective_value(Expansion_Model),\n",
    "            DATA_CENTER_MW,\n",
    "            DATA_CENTER_ZONE,\n",
    "            STRIKE_PRICE,\n",
    "            sum(sample_weight .* dc_gen_vec),\n",
    "            count(x -> x > 1.0, dc_gen_vec),\n",
    "            sum(new_builds.New_MW),\n",
    "            sum(values(gen_by_resource)) / 1e6\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    CSV.write(joinpath(results_dir, \"summary.csv\"), summary)\n",
    "    println(\"  Saved summary.csv\")\n",
    "    \n",
    "    println(\"\\n All results exported to '$(results_dir)/' directory\")\n",
    "else\n",
    "    println(\"\\n Result export disabled (set SAVE_HOURLY_RESULTS = true to enable)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Conclusions and Next Steps\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "This model demonstrates:\n",
    "1. **Demand flexibility has measurable value** - The optimizer strategically curtails data center load during scarcity events\n",
    "2. **Location matters** - Siting flexible loads in renewable-rich zones (West Texas) may provide additional benefits\n",
    "3. **Strike price is critical** - Lower opportunity costs lead to more frequent curtailment\n",
    "4. **Capacity credit** - Flexible loads can defer or reduce the need for new peaking capacity\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "- Add CO₂ emissions tracking and carbon price sensitivity\n",
    "- Model uncertainty (stochastic programming for demand/renewable forecast errors)\n",
    "- Include ancillary services (frequency regulation, reserves)\n",
    "- Multi-year investment timeline with discounting\n",
    "- Compare to alternative flexibility resources (batteries, vehicle-to-grid)\n",
    "- Network congestion analysis and locational marginal pricing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
